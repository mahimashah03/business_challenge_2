{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pylab as plt\nfrom sklearn.metrics import balanced_accuracy_score\nfrom sklearn.tree import plot_tree\nimport sklearn.tree\nfrom sklearn.ensemble import RandomForestClassifier\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nplt.style.use('ggplot')\npd.set_option('max_columns', 200)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-23T01:06:17.000073Z","iopub.execute_input":"2023-02-23T01:06:17.000647Z","iopub.status.idle":"2023-02-23T01:06:17.014241Z","shell.execute_reply.started":"2023-02-23T01:06:17.000594Z","shell.execute_reply":"2023-02-23T01:06:17.012905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')\ntransported = df['Transported'].astype(int)\ndf.insert(1, 'transport_num', transported)\ndf.reindex()\ndf = df.dropna().copy()\ndf.columns","metadata":{"execution":{"iopub.status.busy":"2023-02-23T01:06:18.256502Z","iopub.execute_input":"2023-02-23T01:06:18.256936Z","iopub.status.idle":"2023-02-23T01:06:18.345671Z","shell.execute_reply.started":"2023-02-23T01:06:18.256903Z","shell.execute_reply":"2023-02-23T01:06:18.34439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[['PassengerId', 'HomePlanet', 'CryoSleep', 'Age',\n       'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck',\n       'Transported']].copy()","metadata":{"execution":{"iopub.status.busy":"2023-02-23T01:06:21.684115Z","iopub.execute_input":"2023-02-23T01:06:21.684528Z","iopub.status.idle":"2023-02-23T01:06:21.696228Z","shell.execute_reply.started":"2023-02-23T01:06:21.684492Z","shell.execute_reply":"2023-02-23T01:06:21.694731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# one-hot encoding","metadata":{}},{"cell_type":"code","source":"# One-hot encode categorical features\ndf = pd.get_dummies(df, columns=[\"HomePlanet\", \"VIP\"], drop_first=False)\ndf","metadata":{"execution":{"iopub.status.busy":"2023-02-23T01:06:23.584996Z","iopub.execute_input":"2023-02-23T01:06:23.585477Z","iopub.status.idle":"2023-02-23T01:06:23.628129Z","shell.execute_reply.started":"2023-02-23T01:06:23.585436Z","shell.execute_reply":"2023-02-23T01:06:23.626723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split the dataset into train and test","metadata":{}},{"cell_type":"code","source":"train, test = train_test_split(df, test_size=0.1, random_state=2, shuffle=True)\n\nprint(\"Data shape:\")\nprint(\"train\", train.shape)\nprint(\"test\", test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T01:06:39.570648Z","iopub.execute_input":"2023-02-23T01:06:39.571094Z","iopub.status.idle":"2023-02-23T01:06:39.586166Z","shell.execute_reply.started":"2023-02-23T01:06:39.571055Z","shell.execute_reply":"2023-02-23T01:06:39.584421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model assessment","metadata":{}},{"cell_type":"code","source":"# Make a utility method that we can re-use\n# To easily fit and test out model\nfeatures = [c for c in df.columns if c != \"Transported\"]\n\n\ndef fit_and_test_model(model):\n    '''\n    Trains a model and tests it against both train and test sets\n    '''  \n    global features\n\n    # Train the model\n    model.fit(train[features], train.Transported)\n\n    # Assess its performance\n    # -- Train\n    predictions = model.predict(train[features])\n    train_accuracy = balanced_accuracy_score(train.Transported, predictions)\n\n    # -- Test\n    predictions = model.predict(test[features])\n    test_accuracy = balanced_accuracy_score(test.Transported, predictions)\n\n    return train_accuracy, test_accuracy","metadata":{"execution":{"iopub.status.busy":"2023-02-23T01:06:46.109294Z","iopub.execute_input":"2023-02-23T01:06:46.109721Z","iopub.status.idle":"2023-02-23T01:06:46.121301Z","shell.execute_reply.started":"2023-02-23T01:06:46.109685Z","shell.execute_reply":"2023-02-23T01:06:46.120234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fitting a decision tree","metadata":{}},{"cell_type":"code","source":"# fit a simple tree using only three levels\nmodel = sklearn.tree.DecisionTreeClassifier(random_state=1, max_depth=10) \ndt_train_accuracy, dt_test_accuracy = fit_and_test_model(model)\n\nprint(\"Decision Tree Performance:\")\nprint(\"Train accuracy\", dt_train_accuracy)\nprint(\"Test accuracy\", dt_test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T01:06:48.766717Z","iopub.execute_input":"2023-02-23T01:06:48.767251Z","iopub.status.idle":"2023-02-23T01:06:48.830793Z","shell.execute_reply.started":"2023-02-23T01:06:48.7672Z","shell.execute_reply":"2023-02-23T01:06:48.829576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"# Create a random forest model with two trees\nrandom_forest = RandomForestClassifier( n_estimators=2,\n                                        random_state=2,\n                                        verbose=False)\n\n# Train and test the model\ntrain_accuracy, test_accuracy = fit_and_test_model(random_forest)\nprint(\"Random Forest Performance:\")\nprint(\"Train accuracy\", train_accuracy)\nprint(\"Test accuracy\", test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T01:06:50.513607Z","iopub.execute_input":"2023-02-23T01:06:50.514074Z","iopub.status.idle":"2023-02-23T01:06:50.574404Z","shell.execute_reply.started":"2023-02-23T01:06:50.514036Z","shell.execute_reply":"2023-02-23T01:06:50.572976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Altering the number of trees","metadata":{}},{"cell_type":"code","source":"# n_estimators states how many trees to put in the model\n# We will make one model for every entry in this list\n# and see how well each model performs \nn_estimators = [2, 5, 10, 20, 50]\n\n# Train our models and report their performance\ntrain_accuracies = []\ntest_accuracies = []\n\nfor n_estimator in n_estimators:\n    print(\"Preparing a model with\", n_estimator, \"trees...\")\n\n    # Prepare the model \n    rf = RandomForestClassifier(n_estimators=n_estimator, \n                                random_state=2, \n                                verbose=False)\n    \n    # Train and test the result\n    train_accuracy, test_accuracy = fit_and_test_model(rf)\n\n    # Save the results\n    test_accuracies.append(test_accuracy)\n    train_accuracies.append(train_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T01:06:52.324045Z","iopub.execute_input":"2023-02-23T01:06:52.324673Z","iopub.status.idle":"2023-02-23T01:06:53.324772Z","shell.execute_reply.started":"2023-02-23T01:06:52.324605Z","shell.execute_reply":"2023-02-23T01:06:53.323502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Altering the minimum number of samples for split parameter\n","metadata":{}},{"cell_type":"code","source":"# Shrink the training set temporarily to explore this\n# setting with a more normal sample size\nfull_trainset = train\ntrain = full_trainset[:1000] # limit to 1000 samples\n\nmin_samples_split = [2, 10, 20, 50, 100, 500]\n\n# Train our models and report their performance\ntrain_accuracies = []\ntest_accuracies = []\n\nfor min_samples in min_samples_split:\n    print(\"Preparing a model with min_samples_split = \", min_samples)\n\n    # Prepare the model \n    rf = RandomForestClassifier(n_estimators=20,\n                                min_samples_split=min_samples,\n                                random_state=2, \n                                verbose=False)\n    \n    # Train and test the result\n    train_accuracy, test_accuracy = fit_and_test_model(rf)\n\n    # Save the results\n    test_accuracies.append(test_accuracy)\n    train_accuracies.append(train_accuracy)\n\n\n# Rol back the trainset to the full set\ntrain = full_trainset","metadata":{"execution":{"iopub.status.busy":"2023-02-23T01:06:55.068108Z","iopub.execute_input":"2023-02-23T01:06:55.068546Z","iopub.status.idle":"2023-02-23T01:06:55.447744Z","shell.execute_reply.started":"2023-02-23T01:06:55.068507Z","shell.execute_reply":"2023-02-23T01:06:55.446409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Altering the model depth","metadata":{}},{"cell_type":"code","source":"# Shrink the training set temporarily to explore this\n# setting with a more normal sample size\nfull_trainset = train\ntrain = full_trainset[:500] # limit to 500 samples\n\nmax_depths = [2, 4, 6, 8, 10, 15, 20, 50, 100]\n\n# Train our models and report their performance\ntrain_accuracies = []\ntest_accuracies = []\n\nfor max_depth in max_depths:\n    print(\"Preparing a model with max_depth = \", max_depth)\n\n    # Prepare the model \n    rf = RandomForestClassifier(n_estimators=20,\n                                max_depth=max_depth,\n                                random_state=2, \n                                verbose=False)\n    \n    # Train and test the result\n    train_accuracy, test_accuracy = fit_and_test_model(rf)\n\n    # Save the results\n    test_accuracies.append(test_accuracy)\n    train_accuracies.append(train_accuracy)\n\n# Rol back the trainset to the full set\ntrain = full_trainset","metadata":{"execution":{"iopub.status.busy":"2023-02-23T01:06:56.953847Z","iopub.execute_input":"2023-02-23T01:06:56.954255Z","iopub.status.idle":"2023-02-23T01:06:57.443392Z","shell.execute_reply.started":"2023-02-23T01:06:56.954222Z","shell.execute_reply":"2023-02-23T01:06:57.44236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# An optimised model","metadata":{}},{"cell_type":"code","source":"# Prepare the model \nrf = RandomForestClassifier(n_estimators=200,\n                            max_depth=128,\n                            #max_features=25,\n                            min_samples_split=2,\n                            random_state=2, \n                            verbose=False)\n\n# Train and test the result\nprint(\"Training model. This may take 1 - 2 minutes\")\ntrain_accuracy, test_accuracy = fit_and_test_model(rf)\n\n# Print out results, compared to the decision tree\ndata = {\"Model\": [\"Decision tree\",\"Final random forest\"],\n        \"Train sensitivity\": [dt_train_accuracy, train_accuracy],\n        \"Test sensitivity\": [dt_test_accuracy, test_accuracy]\n        }\n\npd.DataFrame(data, columns = [\"Model\", \"Train sensitivity\", \"Test sensitivity\"])","metadata":{"execution":{"iopub.status.busy":"2023-02-23T01:06:59.101386Z","iopub.execute_input":"2023-02-23T01:06:59.101829Z","iopub.status.idle":"2023-02-23T01:07:01.156586Z","shell.execute_reply.started":"2023-02-23T01:06:59.101784Z","shell.execute_reply":"2023-02-23T01:07:01.155161Z"},"trusted":true},"execution_count":null,"outputs":[]}]}